# SAMBHAV: The Future of Inclusive Communication ðŸš€
> *Bridging the gap between Sound and Silence with Emotion-Aware AI.*

![Imagine Cup](https://img.shields.io/badge/Imagine%20Cup-2026%20Candidate-blue?style=for-the-badge&logo=microsoft)
![Status](https://img.shields.io/badge/Status-Production%20Ready-success?style=for-the-badge)
![Tech](https://img.shields.io/badge/Tech-Next.js%20%7C%20MediaPipe%20%7C%20WebLLM-black?style=for-the-badge)

## ðŸŒŸ Vision
**SAMBHAV** (Possibility) is a next-generation communication bridge designed for the Deaf and Hard-of-Hearing community. Unlike traditional tools that simply translate words, SAMBHAV understands **Context**, **Emotion**, and **Urgency**.

We don't just translate signs; we translate *intent*.

---

## ðŸ”¥ Key Features

### ðŸ§  1. Emotion-Aware Translation
Understanding that *how* you say something matters as much as *what* you say.
- **Happy Face + "Hello"** â†’ "Hello! So glad to see you! ðŸ˜Š"
- **Fearful Face + "Help"** â†’ "EMERGENCY! I need help immediately! ðŸš¨"
*Powered by MediaPipe Face Mesh & Geometrical Fusion.*

### ðŸŒ 2. Hyper-Local Multilingual Voice
Breaking language barriers within the region.
- Instantly switch voice output between **English (US)**, **Hindi (IN)**, and more.
- Native accent support for natural interaction.

### ðŸš¨ 3. Life-Saving Emergency Mode
- **Auto-Trigger**: Detects sustained "Fist" âœŠ or "Help" gestures.
- **Action**: Flashes Red Alert UI and broadcasts a high-volume emergency plea.

### ðŸ¥ 4. Smart Context Engines
Adaptive vocabulary based on environment:
- **ðŸ¥ Hospital Mode**: Prioritizes medical terms ("Pain", "Doctor", "Water").
- **ðŸŽ“ Classroom Mode**: Optimization for academic queries.
- **ðŸ›’ Shop Mode**: Quick transactions and negotiation.

---

## ðŸ› ï¸ Tech Stack
- **Frontend**: Next.js 15 (App Router), Tailwind CSS, Framer Motion
- **AI/CV**: MediaPipe Hands, MediaPipe Face Mesh (Client-Side Edge AI)
- **Heuristics**: Geometric Vector Analysis for Zero-Latency recognition
- **Speech**: Web Speech API (Synthesis)

---

## ðŸš€ Getting Started

### Prerequisites
- Node.js 18+
- Webcam

### Installation
```bash
# Clone the repository
git clone https://github.com/ABHISHEK-DBZ/imo.git

# Navigate to directory
cd frontend

# Install dependencies
npm install

# Run Development Server
npm run dev
```

Open [http://localhost:3000/app](http://localhost:3000/app) with your browser to see the result.

---

## ðŸ¤ Contributing
1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ðŸ† Use Case for Imagine Cup
This project addresses **Accessibility** and **AI for Good**. It runs entirely in the browser (Edge AI), ensuring privacy and low-latency performance without heavy server costs.

> "Technology is best when it brings people together."
